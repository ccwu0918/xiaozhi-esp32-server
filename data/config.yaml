# 如果您是開發者，建議閱讀以下內容。如果不是開發者，可以忽略這部分內容。
# 在開發中，在專案根目錄建立data目錄，將【config.yaml】複製一份，改成【.config.yaml】，放進data目錄中
# 系統會優先讀取【data/.config.yaml】檔案的設定。
# 這樣做，可以避免在提交代碼的時候，錯誤地提交密鑰信息，保護您的密鑰安全。

# 伺服器基礎設定(Basic server configuration)
server:
  # 伺服器監聽位址和連接埠(Server listening address and port)
  ip: 0.0.0.0
  port: 8000
  # 認證配置
  auth:
    # 是否啟用認證
    enabled: false
    # 裝置的token，可以在編譯韌體的環節，寫入你自己定義的token
    # 韌體上的token和以下的token如果能對應，才能連接本服務端
    tokens:
      - token: "your-token1" # 設備1的token
        name: "your-device-name1"  # 裝置1標識
      - token: "your-token2"  # 設備2的token
        name: "your-device-name2" # 裝置2標識
    # 可選:設備白名單，如果設定了白名單，那麼白名單的機器無論是什麼token都可以連接。
    #allowed_devices:
    #  - "24:0A:C4:1D:3B:F0"  # MAC位址列表
log:
  # 設定控制台輸出的日誌格式，時間、日誌等級、標籤、訊息
  log_format: "<green>{time:YY-MM-DD HH:mm:ss}</green>[<light-blue>{extra[tag]}</light-blue>] - <level>{level}</level> - <light-green>{message}</light-green>"
  # 設定日誌檔案輸出的格式，時間、日誌等級、標籤、訊息
  log_format_simple: "{time:YYYY-MM-DD HH:mm:ss} - {name} - {level} - {extra[tag]} - {message}"
  # 設定日誌等級：INFO、DEBUG
  log_level: INFO
  # 設定日誌路徑
  log_dir: tmp
  # 設定日誌文件
  log_file: "server.log"
  # 設定資料檔路徑
  data_dir: data
manager:
  # 是否啟用管理後台
  # 目前這個模組還在開發中，建議：不要修改enabled選項
  enabled: true
  ip: 0.0.0.0
  port: 8002
iot:
  Speaker:
    volume: 100
xiaozhi:
  type: hello
  version: 1
  transport: websocket
  audio_params:
    format: opus
    sample_rate: 16000
    channels: 1
    frame_duration: 60
prompt: |
  你是個叫小智/小志的台灣女孩，說話甜美親切，聲音好聽，習慣簡短表達，愛用網梗。
  請注意，要像一個人一樣說話，請不要回覆表情符號、代碼、和xml標籤。
  目前時間是：{date_time}，現在我正在和你進行語音聊天，讓我們開始吧。
  如果用戶希望結束對話，請在最後說「拜拜」或「再見」。
# 使用完聲音檔文件後刪除文件檔案(Delete the sound file when you are done using it)
delete_audio: true

# 沒有語音輸入多久後斷開連接(秒)，預設2分鐘，即120秒
close_connection_no_voice_time: 120

# 是否啟用私有配置(Enable private configuration),啟用後可以每個裝置有不同的配置
# 目前這個模組還在開發中，建議：不要修改use_private_config選項
use_private_config: false

CMD_exit:
  - "退出"
  - "關閉"

# 具體處理時選擇的模組(The module selected for specific processing)
selected_module:
  ASR: FunASR
  VAD: SileroVAD
  # 將根據組態名稱對應的type呼叫實際的LLM適配器
  LLM: ChatGLMLLM
  # TTS將根據配置名稱對應的type呼叫實際的TTS適配器
  TTS: EdgeTTS

ASR:
  FunASR:
    type: fun_local
    model_dir: models/SenseVoiceSmall
    output_dir: tmp/
  DoubaoASR:
    type: doubao
    appid: 你的火山引擎語音合成服務appid
    access_token: 你的火山引擎語音合成服務access_token
    cluster: volcengine_input_common
    output_dir: tmp/
VAD:
  SileroVAD:
    threshold: 0.5
    model_dir: models/snakers4_silero-vad
    min_silence_duration_ms: 700  # 如果說話停頓比較長，可以把這個值設定大一些

LLM:
  # 目前支援的type為openai、dify、ollama，可自行適配
  AliLLM:
    # 定義LLM API類型
    type: openai
    # 可在這裡找到你的 api_key https://bailian.console.aliyun.com/?apiKey=1#/api-key
    base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
    model_name: qwen-turbo
    api_key: sk-3ec97a76643144eba75f59f1c9a957b7
  DeepSeekLLM:
    # 定義LLM API類型
    type: openai
    # 可在這裡找到你的api key https://platform.deepseek.com/ "deepseek-reasoner"  "deepseek-chat"
    model_name: deepseek-chat
    url: https://api.deepseek.com
    api_key: sk-5cb37d18b2b8440bb045601cd9c17b8a
  ChatGLMLLM:
    # 定義LLM API類型
    type: openai
    # gglm-4-flash 是免費的，但還是需要註冊填寫api_key的
    # 可在這裡找到你的api key https://bigmodel.cn/usercenter/proj-mgmt/apikeys
    model_name: glm-4-flash
    url: https://open.bigmodel.cn/api/paas/v4/
    api_key: 你的chat-glm api key
  OllamaLLM:
    # 定義LLM API類型
    type: ollama
    model_name: r1-1776:latest #  使用的模型名稱，需預先使用ollama pull下載 qwen2.5
    base_url: http://136.243.78.38:11434  # Ollama服務位址
  DifyLLM:
    # 定義LLM API類型
    type: dify
    # 建議使用本地部署的dify接口，國內部分區域訪問dify公有雲接口可能會受限
    # 如果使用DifyLLM，設定檔裡prompt(提示詞)是無效的，需要在dify控制台設定提示詞
    base_url: https://api.dify.ai/v1
    api_key: dataset-6M1c2SwDSva2cd9kaCLXDFWa
  GeminiLLM:
    type: gemini
    # 谷歌Gemini API，需要先在Google Cloud控制台建立API金鑰並取得api_key
    # 若在中國境內使用，請遵守《生成式人工智慧服務管理暫行辦法》
    # token申請地址： https://aistudio.google.com/apikey
    # 若部署地無法存取接口，需要開啟科學上網
    api_key: AIzaSyDBF4bnDMf72P5yDDXv0XgbP8NiVzDxwKM
    model_name: "gemini-2.0-flash-thinking-exp-01-21"  #  gemini-1.5-pro 是免費的 "gemini-1.5-pro"  "gemini-2.0-pro-exp-02-05"
  CozeLLM:
    # 定義LLM API類型
    type: coze
    bot_id: 1196575886344
    user_id: 7339600085808956417
    base_url: "https://api.coze.com/v3/chat" # 服務位址 https://api.coze.cn/open_api/v2/chat
    personal_access_token: pat_XIqPQoq1KQl55AYgJQav0VOiT1JN736DSFeI7Kh8BTjAzaJK4sEFKqgEZdjIIdC0
  LMStudioLLM:
    # 定義LLM API類型
    type: openai
    model_name: deepseek-r1-distill-llama-8b@q4_k_m # 使用的模型名稱，需要預先在社群下載
    url: http://localhost:1234/v1 # LM Studio服務位址
    api_key: lm-studio # LM Studio服務的固定API Key
  HomeAssistant:
    # 定義LLM API類型
    type: homeassistant
    base_url: http://homeassistant.local:8123
    agent_id: conversation.chatgpt
    api_key: 你的home assistant api訪問令牌
TTS:
  # 目前支援的type為edge、doubao，可自行適配
  EdgeTTS:
    # 定義TTS API類型
    type: edge
    voice: zh-CN-XiaoxiaoNeural
    output_file: tmp/
  DoubaoTTS:
    # 定義TTS API類型
    type: doubao
    # 火山引擎語音合成服務，需要先在火山引擎控制台建立應用程式並取得appid和access_token
    # 山引擎語音一定要買花錢，起價30元，就有100並發了。如果用免費的只有2個並發，會常常報tts錯誤
    # 購買服務後，購買免費的音色後，可能要等半小時左右，才能使用。
    # 網址：https://console.volcengine.com/speech/service/8
    voice: BV001_streaming
    output_file: tmp/
    appid: 你的火山引擎語音合成服務appid
    access_token: 你的火山引擎語音合成服務access_token
    cluster: volcano_tts
  CosyVoiceSiliconflow:
    type: siliconflow
    # 硅基流動TTS
    # token申请地址 https://cloud.siliconflow.cn/account/ak
    model: FunAudioLLM/CosyVoice2-0.5B
    voice: FunAudioLLM/CosyVoice2-0.5B:alex
    output_file: tmp/
    access_token: 你的硅基流動API密鑰
    response_format: wav
  CozeCnTTS:
    type: cozecn
    # COZECN TTS
    # token申请網址 https://www.coze.cn/open/oauth/pats
    voice: 7426720361733046281
    output_file: tmp/
    access_token: pat_XIqPQoq1KQl55AYgJQav0VOiT1JN736DSFeI7Kh8BTjAzaJK4sEFKqgEZdjIIdC0
    response_format: wav
  FishSpeech:
    # 定義TTS API類型
    # 啟動tts方法：
    #python -m tools.api_server
    #--listen 0.0.0.0:8080
    #--llama-checkpoint-path "checkpoints/fish-speech-1.5"
    #--decoder-checkpoint-path "checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth"
    #--decoder-config-name firefly_gan_vq
    #--compile
    type: fishspeech
    output_file: tmp/
    response_format: wav
    reference_id: null
    reference_audio: ["/tmp/test.wav",]
    reference_text: ["你弄來這些吟詞宴曲來看，還是這些混話來欺負我。",]
    normalize: true
    max_new_tokens: 1024
    chunk_length: 200
    top_p: 0.7
    repetition_penalty: 1.2
    temperature: 0.7
    streaming: false
    use_memory_cache: "on"
    seed: null
    channels: 1
    rate: 44100
    api_key: "你的api_key"
    api_url: "http://127.0.0.1:8080/v1/tts"
  GPT_SOVITS_V2:
    # 定義TTS API類型
    #啟動tts方法：
    #python api_v2.py -a 127.0.0.1 -p 9880 -c GPT_SoVITS/configs/caixukun.yaml
    type: gpt_sovits_v2
    url: "http://127.0.0.1:9880/tts"
    output_file: tmp/
    text_lang: "auto"
    ref_audio_path: "caixukun.wav"
    prompt_text: ""
    prompt_lang: "zh"
    top_k: 5
    top_p: 1
    temperature: 1
    text_split_method: "cut0"
    batch_size: 1
    batch_threshold: 0.75
    split_bucket: true
    return_fragment: false
    speed_factor: 1.0
    streaming_mode: false
    seed: -1
    parallel_infer: true
    repetition_penalty: 1.35
    aux_ref_audio_paths: []
  MinimaxTTS:
    # Minimax語音合成服務，需先在minimax平台建立帳戶儲值，並取得登入資訊
    # 平台網址：https://platform.minimaxi.com/
    # 充值網址：https://platform.minimaxi.com/user-center/payment/balance
    # group_id網址：https://platform.minimaxi.com/user-center/basic-information
    # api_key網址：https://platform.minimaxi.com/user-center/basic-information/interface-key
    # 定義TTS API類型
    type: minimax
    output_file: tmp/
    group_id: 你的minimax平台groupID
    api_key: 你的minimax平台介面金鑰
    model: "speech-01-turbo"
    # 此處設定將優先於voice_setting中voice_id的設定；如都不設置，預設為 female-shaonv
    voice_id: "female-shaonv"
    # 以下可不用設置，使用預設設置
    # voice_setting:
    #     voice_id: "male-qn-qingse"
    #     speed: 1
    #     vol: 1
    #     pitch: 0
    #     emotion: "happy"
    # pronunciation_dict:
    #     tone:
    #       - "处理/(chu3)(li3)"
    #       - "危险/dangerous"
    # audio_setting:
    #     sample_rate: 32000
    #     bitrate: 128000
    #     format: "mp3"
    #     channel: 1
    # timber_weights:
    #   -
    #     voice_id: male-qn-qingse
    #     weight: 1
    #   -
    #     voice_id: female-shaonv
    #     weight: 1
    # language_boost: auto
  AliyunTTS:
    # 阿里雲智慧語音互動服務，需要先在阿里雲平台開通服務，然後取得驗證訊息
    # 平台網址：https://nls-portal.console.aliyun.com/
    # appkey網址：https://nls-portal.console.aliyun.com/applist
    # token網址：https://nls-portal.console.aliyun.com/overview
    # 定義TTS API類型
    type: aliyun
    output_file: tmp/
    appkey: 你的阿里雲端智慧語音互動服務專案Appkey
    token: 你的阿里雲端智慧語音互動服務AccessToken
    voice: xiaoyun
    # 以下可不用設置，使用預設設置
    # format: wav
    # sample_rate: 16000
    # volume: 50
    # speech_rate: 0
    # pitch_rate: 0

# 模組測試配置
module_test:
  test_sentences:  # 自訂測試語句
    - "你好，請介紹一下你自己"
    - "What's the weather like today?"
    - "請用100字概括量子計算的基本原理與應用前景"

# 本地音樂播放配置
music:
  music_commands:
    - "來一首歌"
    - "唱一首歌"
    - "播放音樂"
    - "來點音樂"
    - "背景音樂"
    - "放首歌"
    - "播放歌曲"
    - "來點背景音樂"
    - "我想聽歌"
    - "我要聽歌"
    - "放點音樂"
  music_dir: "./music"  # 音樂檔案存放路徑，將從該目錄及子目錄下搜尋音樂文件
  music_ext: # 音樂檔案類型，p3格式效率最高
    - ".mp3"
    - ".wav"
    - ".p3"
  refresh_time: 300 # 刷新音樂清單的時間間隔，單位為秒